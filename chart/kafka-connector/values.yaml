# The Kafka connector is an OpenFaaS Pro feature
#
# Purchase a license at https://openfaas.com/support/

# You will need to create a license named "openfaas-license" - see the
# chart README for detailed instructions.

image: ghcr.io/openfaasltd/kafka-connector:0.7.2

# Output detailed logs from the consumer group's lifecycle
sessionLogging: true

replicas: 1

# Max timeout for a function
upstreamTimeout: 2m

# interval for rebuilding the map of functions and topics
rebuildInterval: 30s

# Use with slow consumers or long running functions
asyncInvocation: false

# Set either a single topic, or multiple with a comma separating each
# topics: payment.requested
# topics: payment.requested,customer.created,invoice.generated
topics: faas-request

# Your Kafka broker
brokerHost: kf-kafka:9092

# 1MB = 1024 bytes * 1024
maxBytes: "1048576"

# HTTP content-type for invoking functions
contentType: text/plain

# Set the consumer group
group: faas-group-1

logs:
  # Log debug messages
  debug: false
  # Set the log format, supports console or json
  format: "console"

# Print the data read from the Kafka topic before invoking functions
printRequestBody: false

# Print the HTTP status of invoked functions
printResponse: true

# Print the data received from invoked functions
printResponseBody: false

# intialOffset for Kafka consumer
#
# "newest" stands for the log head offset, i.e. the offset that will be
# assigned to the next message that will be produced to the partition. You
# can send this to a client's GetOffset method to get this offset, or when
# calling ConsumePartition to start consuming new messages.
#
# "oldest" stands for the oldest offset available on the broker for a
# partition. You can send this to a client's GetOffset method to get this
# offset, or when calling ConsumePartition to start consuming from the
# oldest offset that is still available on the broker.
initialOffset: oldest

# Gateway URL to access API and for invocations
gatewayURL: http://gateway.openfaas:8080

# Basic auth for the gateway
basic_auth: true

nodeSelector: {}

tolerations: []

affinity: {}

resources:
  requests:
    memory: "64Mi"
    cpu: "100m"
  # limits:
  #   memory: "256Mi"

# Encryption
tls: false

# Authentication

## When set to true, create secrets: "kafka-broker-username" and "kafka-broker-password"
saslAuth: false

# kubectl create secret generic \
# kafka-broker-username \
# -n openfaas \
# --from-file broker-username=./broker-username.txt

# kubectl create secret generic \
# kafka-broker-password \
# -n openfaas \
# --from-file broker-password=./broker-password.txt

brokerPasswordSecret: kafka-broker-password
brokerUsernameSecret: kafka-broker-username

## When using a custom CA:

# kubectl create secret generic \
# kafka-broker-ca \
# -n openfaas \
# --from-file broker-ca=./broker-ca.pem

# When using client certs

# kubectl create secret generic \
# kafka-broker-cert \
# -n openfaas \
# --from-file broker-cert=./broker-cert.txt

# kubectl create secret generic \
# kafka-broker-key \
# -n openfaas \
# --from-file broker-key=./broker-key.txt

# Set to empty to disable:

caSecret: ""
certSecret: ""
keySecret: ""
# Or give a name to each to enable

# caSecret: kafka-broker-ca
# certSecret: kafka-broker-cert
# keySecret: kafka-broker-key
